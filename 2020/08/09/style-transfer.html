<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Style Transfer | Mark Danovich</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Style Transfer" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The idea of style transfer is to re-imagine an image in a style of another image by “transferring” its “style” to the image." />
<meta property="og:description" content="The idea of style transfer is to re-imagine an image in a style of another image by “transferring” its “style” to the image." />
<meta property="og:site_name" content="Mark Danovich" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-09T11:40:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Style Transfer" />
<script type="application/ld+json">
{"description":"The idea of style transfer is to re-imagine an image in a style of another image by “transferring” its “style” to the image.","@type":"BlogPosting","headline":"Style Transfer","dateModified":"2020-08-09T11:40:00-05:00","datePublished":"2020-08-09T11:40:00-05:00","url":"/2020/08/09/style-transfer.html","mainEntityOfPage":{"@type":"WebPage","@id":"/2020/08/09/style-transfer.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css" /><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Mark Danovich" /><script async src="https://www.googletagmanager.com/gtag/js?id=UA-10819841-6"></script>
<script>
  window['ga-disable-UA-10819841-6'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10819841-6');
</script>
 




 
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "[%", right: "%]", display: true },
                { left: "$", right: "$", display: false }
            ]
        }
        );
    });
</script>


<script>
    function wrap_img(fn) {
        if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
            var elements = document.querySelectorAll(".post img");
            Array.prototype.forEach.call(elements, function (el, i) {
                if (el.getAttribute("title")) {
                    const caption = document.createElement('figcaption');
                    var node = document.createTextNode(el.getAttribute("title"));
                    caption.appendChild(node);
                    const wrapper = document.createElement('figure');
                    wrapper.className = 'image';
                    el.parentNode.insertBefore(wrapper, el);
                    el.parentNode.removeChild(el);
                    wrapper.appendChild(el);
                    wrapper.appendChild(caption);
                }
            });
        } else { document.addEventListener('DOMContentLoaded', fn); }
    }
    window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        // add link icon to anchor tags
        var elem = document.querySelectorAll(".anchor-link")
        elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script></head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/">Mark Danovich</a><nav class="site-nav">
            <input type="checkbox" id="nav-trigger" class="nav-trigger" />
            <label for="nav-trigger">
                <span class="menu-icon">
                    <svg viewBox="0 0 18 15" width="18px" height="15px">
                        <path
                            d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z" />
                    </svg>
                </span>
            </label>

            <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/snippets.html">Snippets</a></div>
        </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title p-name" itemprop="name headline">Style Transfer</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-08-09T11:40:00-05:00" itemprop="datePublished">
                Aug 9, 2020
            </time>
        </p><p>
            
            
            <a class="category-tags-link" href="/tag/deeplearning">
                deeplearning
            </a>
            |
            
            
            <a class="category-tags-link" href="/tag/pytorch">
                pytorch
            </a>
            
            
        </p>

        

        </header>

    <div class="post-content e-content" itemprop="articleBody">
        <p>The idea of style transfer is to re-imagine an image in a style of another image by “transferring”
its “style” to the image.</p>

<p>The meaning of transferring and style are not obvious and probably even subjective.</p>

<p>One approach was developed by <a href="https://arxiv.org/abs/1508.06576">Gatys, 2015</a>, where deep learning, or convolutional neural networks (CNN) were used.</p>

<p>The idea is relatively simple and the results are definitely appealing and match what most would consider to be a style transfer.</p>

<p>Here I wanted to implement it using PyTorch, following the paper and
the TensorFlow <a href="https://www.tensorflow.org/tutorials/generative/style_transfer">tutorial</a>.</p>

<p>The main innovative idea behind the style transfer method, is that the shallower (first) convolutional (conv layers (or filters) of a CNN, which was pre-trained on a large image dataset such as ImageNet, have learned useful filters to identify generic features in an image, e.g. edges, simple shapes, geometry, colors. Things that we would associate with the style of a painting for example. The deeper layers, on the other hand, since they act on the outputs of the previous layers, they are able to learn more complex features, which are useful to identify specific complex objects, such as eyes, face, etc., features which are more relevant to the actual content of the image.</p>

<p>Given a pre-trained network, the idea is the following:</p>

<ol>
  <li>Choose a style image, and a content image.</li>
  <li>Initialise the final image with either random pixels or start with the content image.</li>
  <li>Run the three images through the network, and extract the intermediate features generated by the shallow conv layers as style features, and the later conv layers as content features.</li>
  <li>Compute the style loss associated with the generated image by comparing it with the style of the style image.</li>
  <li>Compute the content loss associated with the generated image by comparing it with the content of the original image.</li>
  <li>Combine both losses with weights and run back propagation on the generated image, and update it using gradient descent.</li>
</ol>

<p>The final image generated by this process, will have style inspired by the style image as described by the shallow conv layers, and content matching the original image.
THe main point to note here is that unlike conventional CNN related tasks where we train using an input image and a label and update the network’s weights, here the network is fixed and what is trained is the input image, the input image pixels serve as the “weights” which are updated to reduce the loss defined above.</p>

<p>I’ve used Google Colab to run the model, making use of the free GPU.
The Google Colab notebook can be found <a href="https://colab.research.google.com/drive/19E8rrdBRHy6ZpPpfUSv74OOED02himaT">here</a>.</p>

<h2 id="the-code">The code</h2>

<p>Imports:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">notebook</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">models</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set device based on availability (cuda or cpu)
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load vgg19 model. Strip away the classification head, to keep only features
</span><span class="n">vgg</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">vgg19</span><span class="p">().</span><span class="n">features</span>
</code></pre></div></div>

<p>The VGG model was the old style of CNN models, without skip connections, therefore it’s much shallower good enough. Composed of repeated blocks of conv, ReLU and max pooling.
It has the following layers:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sequential</span><span class="p">(</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">13</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">14</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">15</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">16</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">17</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">18</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">19</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">20</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">21</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">22</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">23</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">24</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">25</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">26</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">27</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">28</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">29</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">30</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">31</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">32</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">33</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">34</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="p">(</span><span class="mi">35</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">36</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Creating the model class, inhering from PyTorch’s nn.Module:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StyleTransfer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">StyleTransfer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

    <span class="c1"># Choose the conv layers used for style (lower levels)
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">style_layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">28</span><span class="p">]</span>

    <span class="c1"># Choose the conv layers used for context (deeper levels). Can choose multiple, but it's custom to chose 1.
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">content_layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">21</span><span class="p">]</span>

    <span class="c1"># The vgg model, pretrained and only features (without classification head) and without the layer beyond the content last style layer
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">features</span><span class="p">[:</span><span class="mi">31</span><span class="p">]</span>

    <span class="c1"># In the paper the recommend swapping max pool layers with avg pool.
</span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># The model weights are fixed, we're not gonna backprop them,
</span>    <span class="c1"># therefore can set their requires grad to False.
</span>    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">():</span>
      <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>


  <span class="c1"># Define the model's forward pass
</span>  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>

    <span class="c1"># List to append the style/content features from the intermediate layers
</span>    <span class="n">style_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">content_features</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">layer_index</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">):</span>

      <span class="c1"># pass the image through the layer
</span>      <span class="n">image</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

      <span class="c1"># Append the output only if it's one
</span>      <span class="c1"># of the predefined layers
</span>      <span class="k">if</span> <span class="n">layer_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">style_layers</span><span class="p">:</span>
        <span class="n">style_features</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">layer_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">content_layers</span><span class="p">:</span>
        <span class="n">content_features</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="c1"># return dictionary with content and style
</span>    <span class="k">return</span> <span class="p">{</span><span class="s">'content'</span><span class="p">:</span> <span class="n">content_features</span><span class="p">,</span> <span class="s">'style'</span><span class="p">:</span><span class="n">style_features</span><span class="p">}</span>
</code></pre></div></div>

<h2 id="utility-functions">Utility functions</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_img</span><span class="p">(</span><span class="n">path_to_img</span><span class="p">):</span>
    <span class="s">"""
    Load image using PIL, resize it to have
    maximum dimension of 512, to reduce computation time
    """</span>
    <span class="n">max_dim</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">path_to_img</span><span class="p">)</span>
    <span class="n">image</span><span class="p">.</span><span class="n">thumbnail</span><span class="p">((</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="k">def</span> <span class="nf">prepare_img</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="s">"""
    Prepare image as a tensor with a batch axis, required for loading into the model.
    """</span>

    <span class="c1"># The normalize transform, normalizes
</span>    <span class="c1"># the image to using the Imagenet parameters, on which
</span>    <span class="c1"># VGG was trained.
</span>    <span class="c1"># For each channel: image -&gt; (image - mean)/std
</span>    <span class="n">loader</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span>
      <span class="p">[</span>
       <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
       <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">))</span>
      <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Perform transformation and add batch axis (0)
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">loader</span><span class="p">(</span><span class="n">image</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># move image to the defined device
</span>    <span class="k">return</span> <span class="n">image</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">convert_img</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="s">"""
    Convert a tensor of a batch of a single image to a numpy array
    """</span>
    <span class="c1"># transfer to cpu
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">).</span><span class="n">clone</span><span class="p">()</span>

    <span class="c1"># remove batch axis, turn from tensor to numpy array
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># put channels at the last axis
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># reverse imagenet normalization
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">((</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">((</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">))</span>

    <span class="c1"># clip image pixes between 0 and 1
</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>

<span class="k">def</span> <span class="nf">save_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="s">"""
    Save a numpy array with pixels in range [0,1] as an image
    """</span>
    <span class="c1"># To save image using PIL, need to rescale pixel values to 0 -&gt; 255.
</span>    <span class="n">rescaled</span> <span class="o">=</span> <span class="p">(</span><span class="mf">255.0</span> <span class="o">/</span> <span class="n">image</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">image</span> <span class="o">-</span> <span class="n">image</span><span class="p">.</span><span class="nb">min</span><span class="p">())).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>

    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">rescaled</span><span class="p">,</span> <span class="s">'RGB'</span><span class="p">)</span>

    <span class="n">im</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</code></pre></div></div>

<p>Next we define the loss function, which the network will use to adjust it’s input image in this case, in order to reduce the total loss.
The loss in this case is a combination of 2 contributions: Style loss and content loss, each defined in the functions below. When training we additionally have a weight assigned to the style loss, which will allow to have the style influence more the total loss, and therefore the resulting image.</p>

<p>The content loss is a simple pixel by pixels
mean squared error loss, evaluated between the generated image content layer and the original image content layer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">content_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
  <span class="s">""" Mean square error loss between image pixels """</span>
  <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div>

<p>The trick in the paper is in the choice of the style loss, as it’s not obvious how to properly capture style, which is not a simple pixel by pixel difference.
They used the Gram matrix, which is a form of a correlation matrix between the different channels (or features following the conv layers). The dea is that two images with similar styles will have similar Gram matrices, or similar correlations between the different feature maps generated by the style conv layers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gram_matrix</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="s">"""
    Computes the gram matrix - the matrix of all inner products between all feature maps (channels)
    """</span>
    <span class="c1"># get batch, channels, height width
</span>    <span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">shape</span>

    <span class="c1"># reshape tensor to be channels rows by (height*width) columns
</span>    <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="o">*</span><span class="n">w</span><span class="p">)</span>

    <span class="c1"># matrix multiplication of reshaped image by reshaped image transpose
</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">input</span><span class="p">.</span><span class="n">t</span><span class="p">())</span>

    <span class="c1"># An alternative way: result = torch.einsum('bcij,bdij -&gt; bcd', input, input)
</span>
  <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">style_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
  <span class="s">"""
  mean square error of Gram matrices
  """</span>
  <span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">shape</span>
  <span class="n">gr_inp</span> <span class="o">=</span> <span class="n">gram_matrix</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="n">gr_tar</span> <span class="o">=</span> <span class="n">gram_matrix</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

  <span class="c1"># the loss is the mean squared error between the
</span>  <span class="c1"># Gram matrices, with a normalization of number of pixels
</span>  <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">gr_inp</span><span class="p">,</span> <span class="n">gr_tar</span><span class="p">)</span><span class="o">/</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span><span class="p">)</span>
</code></pre></div></div>

<p>As pointed out in the TensorFlow tutorial, an additional useful loss, is to avoid having sharp differences on a single pixel level, e.g. sharp edges. The suggested variation loss, allows to smooth the generated image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">variation_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
  <span class="s">"""
  smoothness loss, penalizes sharp edges on a one pixel scale
  """</span>

  <span class="c1"># neighboring pixels differences on the horizontal direction
</span>  <span class="n">x_var</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:,:]</span> <span class="o">-</span> <span class="nb">input</span><span class="p">[:,:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>

  <span class="c1"># neighboring pixels differences on the vertical direction
</span>  <span class="n">y_var</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[:,:,:,</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="nb">input</span><span class="p">[:,:,:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="c1"># return the sum of absolute values as the loss
</span>  <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x_var</span><span class="p">))</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">y_var</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="training-loop">Training loop</h2>

<p>In the paper a random image (i.e. pixels normally distributed with mean 0 std 1) was used as the initial input. Here I use the content image as the starting point, which requires less training epochs to get
a decent result.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">cont_img</span><span class="p">,</span>
          <span class="n">style_img</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
          <span class="n">style_ratio</span><span class="o">=</span><span class="mf">1e3</span><span class="p">,</span>
          <span class="n">variation_weight</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
          <span class="n">save_intermediate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
          <span class="n">save_name</span><span class="o">=</span><span class="s">'gen_image'</span><span class="p">):</span>
    <span class="s">"""
    Generates an image by transferring style (style_image_path)
    to a content image (cont_image_path), with the style weight given
    by style_ratio and run epoch number of iterations.
    Images are saved with the name prefix.
    """</span>

    <span class="c1"># create image loader for the model's input i.e.
</span>    <span class="c1"># transforming to tensor and adding batch axis
</span>    <span class="n">cont_img</span> <span class="o">=</span> <span class="n">prepare_img</span><span class="p">(</span><span class="n">cont_img</span><span class="p">)</span>
    <span class="n">style_img</span> <span class="o">=</span> <span class="n">prepare_img</span><span class="p">(</span><span class="n">style_img</span><span class="p">)</span>

    <span class="c1"># The generated image is the input image which
</span>    <span class="c1"># we set as trainable, i.e. requiring gradient calculation
</span>    <span class="n">gen_img</span> <span class="o">=</span> <span class="n">cont_img</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># The random alternative
</span>    <span class="c1"># gen_img = torch.rand_like(cont_img).requires_grad_(True)
</span>
    <span class="c1"># Initialize the style transfer model and move it to the device.
</span>    <span class="c1"># The eval command is needed to let pytorch
</span>    <span class="c1"># know when we are using the model for evaluation and not training.
</span>    <span class="c1"># This only controls things like batch norm and dropout,
</span>    <span class="c1"># which we don't have in this model, but good practice
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">StyleTransfer</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nb">eval</span><span class="p">()</span>

    <span class="c1"># Define optimizer with the learning parameters being the input image pixels and a learning lrate
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">gen_img</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>

    <span class="c1"># Lists to store the epoch losses
</span>    <span class="n">style_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">content_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tot_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Run style and content image through model
</span>    <span class="c1"># the detach() command, removes the passed images from the computation graph,
</span>    <span class="c1"># as we don't need to track gradients for the operations done on them.
</span>    <span class="n">orig_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">cont_img</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">style_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">style_img</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="c1"># Get content features from the content image
</span>    <span class="n">content_target</span> <span class="o">=</span> <span class="n">orig_output</span><span class="p">[</span><span class="s">'content'</span><span class="p">]</span>

    <span class="c1"># Get style feature from the style image
</span>    <span class="n">style_target</span> <span class="o">=</span> <span class="n">style_output</span><span class="p">[</span><span class="s">'style'</span><span class="p">]</span>

    <span class="c1"># Get number of layers for normalisation
</span>    <span class="n">num_style_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">style_target</span><span class="p">)</span>

    <span class="c1"># Start training
</span>    <span class="k">print</span><span class="p">(</span><span class="s">f"Training for </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s"> epochs, with style ratio: </span><span class="si">{</span><span class="n">style_ratio</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">notebook</span><span class="p">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>

        <span class="c1"># Zero the accumulated gradients
</span>        <span class="c1"># on each iteration
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Run the input image through model
</span>        <span class="n">gen_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">gen_img</span><span class="p">)</span>

        <span class="c1"># Get content features for the input image
</span>        <span class="n">gen_content</span> <span class="o">=</span> <span class="n">gen_output</span><span class="p">[</span><span class="s">'content'</span><span class="p">]</span>

        <span class="c1"># Get style features for the input image
</span>        <span class="n">gen_style</span> <span class="o">=</span> <span class="n">gen_output</span><span class="p">[</span><span class="s">'style'</span><span class="p">]</span>

        <span class="c1"># Initialize losses
</span>        <span class="n">style_loss_tot</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">cont_loss_tot</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Compute style loss and add it to total from each feature layer
</span>        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">stl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gen_style</span><span class="p">):</span>
            <span class="n">style_loss_tot</span> <span class="o">+=</span> <span class="n">style_loss</span><span class="p">(</span><span class="n">stl</span><span class="p">,</span> <span class="n">style_target</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

        <span class="c1"># Normalize by number of layers
</span>        <span class="n">style_loss_tot</span> <span class="o">/=</span> <span class="n">num_style_layers</span>

        <span class="c1"># Compute content loss (one layer)
</span>        <span class="n">cont_loss_tot</span> <span class="o">=</span> <span class="n">content_loss</span><span class="p">(</span><span class="n">gen_content</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">content_target</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Compute total loss as a weighted sum of style and content loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">style_ratio</span><span class="o">*</span><span class="n">style_loss_tot</span> <span class="o">+</span> <span class="n">cont_loss_tot</span>

        <span class="c1"># Add variation loss
</span>        <span class="n">loss</span> <span class="o">+=</span> <span class="n">variation_weight</span><span class="o">*</span><span class="n">variation_loss</span><span class="p">(</span><span class="n">gen_img</span><span class="p">)</span>

        <span class="c1"># Perform back propagation (calculate gradients)
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Make gradient descent step
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Track style, content and total loss for plotting
</span>        <span class="n">style_losses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">style_ratio</span><span class="o">*</span><span class="n">style_loss_tot</span><span class="p">)</span>
        <span class="n">content_losses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cont_loss_tot</span><span class="p">)</span>
        <span class="n">tot_losses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="c1"># Optional save intermediate images
</span>        <span class="k">if</span> <span class="n">save_intermediate</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">f"saving image </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
                <span class="n">conv_img</span> <span class="o">=</span> <span class="n">convert_img</span><span class="p">(</span><span class="n">gen_img</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="n">save_image</span><span class="p">(</span><span class="n">conv_img</span><span class="p">,</span> <span class="n">save_name</span> <span class="o">+</span> <span class="s">'.jpg'</span><span class="p">)</span>

    <span class="c1"># Show loss through training process
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">style_losses</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'style loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">content_losses</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'content loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">tot_losses</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'Total loss'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>

    <span class="c1"># Show and save final image
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">conv_img</span> <span class="o">=</span> <span class="n">convert_img</span><span class="p">(</span><span class="n">gen_img</span><span class="p">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conv_img</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'saving final image'</span><span class="p">)</span>
    <span class="n">save_image</span><span class="p">(</span><span class="n">conv_img</span><span class="p">,</span> <span class="n">save_name</span><span class="o">+</span><span class="s">'.jpg'</span><span class="p">)</span>
</code></pre></div></div>

<p>Example:</p>

<p>Define parameters:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># These were chosen by trying what gives desired results
# There is no point going too high with the style loss, as at some point it will
# simply be the entire loss, and as we're starting from the content, it won't
# change much the final output.
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># number of training epochs
</span><span class="n">style_ratio</span> <span class="o">=</span> <span class="mf">1e3</span>  <span class="c1"># the style loss weight relative to content loss
</span><span class="n">content_image</span> <span class="o">=</span> <span class="s">"horses.jpg"</span>
<span class="n">style_image</span> <span class="o">=</span> <span class="s">"stary_night.jpg"</span>
<span class="n">save_name</span> <span class="o">=</span> <span class="s">"horses_stary"</span>  <span class="c1"># filename for the output
</span></code></pre></div></div>

<p>Load content and style images:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cont_img</span> <span class="o">=</span> <span class="n">load_img</span><span class="p">(</span><span class="n">content_image</span><span class="p">)</span>
<span class="n">style_img</span> <span class="o">=</span> <span class="n">load_img</span><span class="p">(</span><span class="n">style_image</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cont_img</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">style_img</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="run-training">Run training</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">(</span><span class="n">cont_img</span><span class="p">,</span>
    <span class="n">style_img</span><span class="p">,</span>
    <span class="n">style_ratio</span><span class="o">=</span><span class="n">style_ratio</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">save_name</span><span class="o">=</span><span class="n">save_name</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="examples">Examples:</h2>

<table>
<tr>
<td>Content Image: Horses</td>
<td>Style Image: Starry night by Vincent Van Gogh</td>
</tr>
<tr>
<td> <img src="/assets/styletransfer/horses.jpg" style="width: 350px;" /> </td>
<td> <img src="/assets/styletransfer/stary_night.jpg" style="width: 350px;" /> </td>
</tr>
</table>

<p>Result:</p>

<p><img src="/assets/styletransfer/horses_stary.jpg" alt="horses" /></p>

<p>Here I used <code class="highlighter-rouge">epochs=200</code>. Training for more epochs will further reduce the loss making the image match the style more and more at the expanse of losing the content information.</p>

<table>
<tr>
<td>Content Image: Horses</td>
<td>Style Image: The Scream by Munch</td>
</tr>
<tr>
<td> <img src="/assets/styletransfer/horses.jpg" style="width: 350px;" /> </td>
<td> <img src="/assets/styletransfer/munch.jpg" style="width: 350px;" /> </td>
</tr>
</table>

<p>Result:</p>

<p><img src="/assets/styletransfer/horses_munch.jpg" alt="horsesmunch" /></p>

<table>
<tr>
<td>Content Image: Horses</td>
<td>Style Image: The Great Wave</td>
</tr>
<tr>
<td> <img src="/assets/styletransfer/horses.jpg" style="width: 350px;" /> </td>
<td> <img src="/assets/styletransfer/great_wave.jpg" style="width: 350px;" /> </td>
</tr>
</table>

<p>Result:</p>

<p><img src="/assets/styletransfer/horses_wave.jpg" alt="horses" /></p>

<table>
<tr>
<td>Content Image: Horses</td>
<td>Style Image: Picasso</td>
</tr>
<tr>
<td> <img src="/assets/styletransfer/horses.jpg" style="width: 350px;" /> </td>
<td> <img src="/assets/styletransfer/picasso.jpg" style="width: 350px;" /> </td>
</tr>
</table>

<p>Result:</p>

<p><img src="/assets/styletransfer/horses_picasso.jpg" alt="horsespicasso" /></p>

<p>In the next example I used epochs = 1000 and style_ratio = 1e5:</p>

<table>
<tr>
<td>Content Image: Edinburgh</td>
<td>Style Image: Starry Night by Vincent Van Gogh</td>
</tr>
<tr>
<td> <img src="/assets/styletransfer/edinb.jpg" style="width: 350px;" /> </td>
<td> <img src="/assets/styletransfer/stary_night.jpg" style="width: 350px;" /> </td>
</tr>
</table>

<p>Result:</p>

<p><img src="/assets/styletransfer/edinb_starry.jpg" alt="edinbstarry" /></p>

<p>An example (log) loss curve from the training, showing that given the weights, the loss is primarily driven by the style loss:</p>

<p><img src="/assets/styletransfer/loss_curve.png" alt="loss" /></p>

    </div><a class="u-url" href="/2020/08/09/style-transfer.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My personal website and blog. Life, Science, Programming and Data Science.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/markd87" title="markd87"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/mmasaniad" title="mmasaniad"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
