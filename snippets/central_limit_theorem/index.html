<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Central Limit Theorem intuition | Mark Danovich</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Central Limit Theorem intuition" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A nice information theoretic intuition for the central limit theorem I’ve recently read about has to do with maximum entropy." />
<meta property="og:description" content="A nice information theoretic intuition for the central limit theorem I’ve recently read about has to do with maximum entropy." />
<meta property="og:site_name" content="Mark Danovich" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-14T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Central Limit Theorem intuition" />
<script type="application/ld+json">
{"headline":"Central Limit Theorem intuition","dateModified":"2021-02-14T00:00:00-06:00","datePublished":"2021-02-14T00:00:00-06:00","description":"A nice information theoretic intuition for the central limit theorem I’ve recently read about has to do with maximum entropy.","mainEntityOfPage":{"@type":"WebPage","@id":"/snippets/central_limit_theorem/"},"@type":"BlogPosting","url":"/snippets/central_limit_theorem/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css" /><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Mark Danovich" /><script async src="https://www.googletagmanager.com/gtag/js?id=UA-10819841-6"></script>
<script>
  window['ga-disable-UA-10819841-6'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-10819841-6');
</script>
 




 
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "[%", right: "%]", display: true },
                { left: "$", right: "$", display: false }
            ]
        }
        );
    });
</script>


<script>
    function wrap_img(fn) {
        if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
            var elements = document.querySelectorAll(".post img");
            Array.prototype.forEach.call(elements, function (el, i) {
                if (el.getAttribute("title")) {
                    const caption = document.createElement('figcaption');
                    var node = document.createTextNode(el.getAttribute("title"));
                    caption.appendChild(node);
                    const wrapper = document.createElement('figure');
                    wrapper.className = 'image';
                    el.parentNode.insertBefore(wrapper, el);
                    el.parentNode.removeChild(el);
                    wrapper.appendChild(el);
                    wrapper.appendChild(caption);
                }
            });
        } else { document.addEventListener('DOMContentLoaded', fn); }
    }
    window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        // add link icon to anchor tags
        var elem = document.querySelectorAll(".anchor-link")
        elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script></head>
<body><header class="site-header">

    <div class="wrapper"><a class="site-title" rel="author" href="/">Mark Danovich</a><nav class="site-nav">
            <input type="checkbox" id="nav-trigger" class="nav-trigger" />
            <label for="nav-trigger">
                <span class="menu-icon">
                    <svg viewBox="0 0 18 15" width="18px" height="15px">
                        <path
                            d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z" />
                    </svg>
                </span>
            </label>

            <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/snippets.html">Snippets</a></div>
        </nav></div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <header class="post-header">
        <h1 class="post-title p-name" itemprop="name headline">Central Limit Theorem intuition</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-14T00:00:00-06:00" itemprop="datePublished">
                Feb 14, 2021
            </time>
        </p><p>
            
        </p>

        

        </header>

    <div class="post-content e-content" itemprop="articleBody">
        <p>A nice information theoretic intuition for the central limit theorem I’ve recently read about has to do with maximum entropy.</p>

<p>The central limit theorem (CLT) says that the sum of independent random variables tends to a Gaussian distribution with given means and standard deviation.</p>

<p>For a given class of distributions (e.g. finite known n-moments), a <a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution">maximum entropy distribution</a> is the distribution with least prior-information, where the entropy is defined as,</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></msubsup><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">H(X) = -\int_{-\infty}^{\infty} p(x)\log p(x) dx.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.384573em;vertical-align:-0.970281em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.414292em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970281em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mord">.</span></span></span></span></span>

<p>The maximum entropy distribution with finite mean and variance is the <strong>Gaussian distribution</strong>.</p>

<p>Therefore if a random variable is the average of multiple independent random variables, then we know the mean and variance but not any other moments, therefore within this class, the distribution with highest entropy or most uncertainty or least prior-information is the Gaussian distribution which is the CLT result and what we see in nature.</p>

    </div><a class="u-url" href="/snippets/central_limit_theorem/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My personal website and blog. Life, Science, Programming and Data Science.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/markd87" title="markd87"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/mmasaniad" title="mmasaniad"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
